    Ms. Landau. Thank you. Mr. Chairman and Members of the Committee, thank you very much for the opportunity to testify today.    The FBI has pitched this battle as one of security versus privacy, but as a number of the Members have already observed, it's really about security versus security. We have a national security threat going on, and we haven't solved the problem at all. What have smartphones got to do with it? Absolutely everything. Smartphones hold our photos and music, our notes and calendars, much of that information sensitive, especially the photos.    Smartphones are increasingly wallets, and they give us access to all sorts of accounts, bank accounts, Dropbox, and so on. Many people store proprietary business information on their smartphones--their personal smartphones--even though they know they shouldn't.    Now, NSA will tell you that stealing login credentials is the most effective way into a system. In fact, Rob Joyce of the Tailored Access Operation said so in a public talk a month ago.    Here's where smartphones are extremely important. They are poised to become authenticators to a wide variety of systems--services. In fact, they're already being used that way, including at some high-placed government agencies.    Now, District Attorney Vance will tell you that law--has said that large scale data breaches have nothing to do with smartphone encryption, but that's not true. Look at today's New York Times, where there's a story about the attack on the Ukrainian power grid. How did it start? It started by the theft of login credentials of system operators. We've got to solve the login authentication problem, and smartphones are actually our best way forward to do it, but not if it's easy to get into the data of the smartphones.    Now, the Committee has already observed that there are many phones that will go through the process of being unlocked, not just the one in San Bernardino. And what that means for Apple is that it's going to have to develop a routine to do so.    Now, what happens when you have--when you sign a piece of code to update a phone and you're signing a piece of code that's an operating system or firm where you do it once--you do it occasionally. It's a whole ritual, and there are very senior people involved. But if you're dealing with phones that are daily being updated in order to solve law enforcement cases, then what happens is you develop a routine. You get a Web page, you get a low level employee to supervise it, and then it becomes a process that's easy to subvert. I have lots of respect for Apple's security, but not when it becomes a routine process to build an update for a phone. And what will happen is organized crime or a nation-state will do so using an update to then hack into a phone, maybe the phone of the Secretary or the chief of the Federal Reserve, maybe a phone of an HVAC employee who's going to go service a powerplant. What we're going to do is decrease our security. That's the security risk that's coming from the requests.    Now, I get that law enforcement wants data protection that allows them access under legal authorization, but an NSA colleague once remarked to me that, while his agency had the right to break into certain systems, no one ever guaranteed that that right would be easy to do so.    The problem is when you build a way in for someone who isn't the owner to get at the data, well, you've built a way in for somebody else to get in as well.    Let me go to CALEA for a moment. CALEA is a security nightmare. I know that Congress didn't intend it that way, but that's what it is. If you ask the signals intelligence people, they will tell you: there are many ways for nefarious sorts to take advantage of the opening offered by law enforcement.    Instead of embracing the communications and device security we so badly need, law enforcement has been pressing to preserve 20th century investigative techniques; meanwhile, our enemies are using 21st century technologies against us.    The FBI needs to take a page from the NSA. You may recall that, in the late 1990's, the NSA was complaining it was going deaf from encrypted calls. Well, they've obviously improved their technology a great deal. According to Mike McConnell, from that time until now, NSA has had better SIGINT than any time in history.    What we need is law enforcement to develop 21st century capabilities for conducting electronic surveillance. Now, the FBI already has some excellent people and expertise, but FBI investment and capacity is not at the scale and level necessary. Rather than asking industry to weaken protections, law enforcement must instead development the capability for conducting sophisticated investigations themselves. Congress can help. The FBI needs an investigative center with agents with deep technical understanding of modern telecommunications technology and also, because all phones are computers, modern computer--deep expertise in computer science. There will need to be teams of researchers who understand various types of fielded devices. They'll need to know where technology is and where it will be in 6 months and where it will be in 2 to 5 years, communications technology in 2 to 5 years, so that they can develop the surveillance technologies themselves.    Expertise need not be in-house. The FBI could pursue a solution where they develop some of their own expertise and closely managed contractors to do some of the work, but however the Bureau pursues a solution, it must develop modern, state-of-the-art capabilities. It must do rather than trying to get industry to weaken security.    Your job is to help the FBI build such capabilities, determine the most efficient and effective way that such capabilities could be utilized by State and local law enforcement, for they don't have the resources to develop that themselves and to also fund that capabilities. That's the way forward that does not put our national security at risk. It enables law enforcement investigations while encouraging industry to do all it can do to develop better, more effective technologies for securing data and devices. That is a win-win and where we should be going. Thank you.    Ms. Landau. Encryption has existed--for centuries. And, in particular, there have been fights over encryption and the use of encryption in the 1970's about publication; in the 1980's about whether NIST or the NSA would control the development of encryption for nonnational security agencies; in the 1990's about whether there would be export controls on devices with strong encryption. The White House changed those rules in 2000.    We expected to see widespread use of strong encryption on devices and on applications, and the technologists' response to Apple is: What took you guys so long? How, in the face of all the cybersecurity problems that we've had, did it take industry so very long to do this?    Well, as our technical expert, let me ask you this: Is there any functional difference between asking Apple to break its own encryption, and what the FBI has demanded in California?    Ms. Landau. I'm sorry. Asking Apple to break--I don't quite understand the question.    Ms. Landau. What Apple is being asked to do is to subvert the security controls and go around. So it's not breaking the encryption, but it's subverting its own security controls.    Ms. Landau. And is there any functional difference between that and----    Ms. Landau. What it's demanded in California is that Apple subvert its own security controls.    Ms. Landau. Absolutely not. Absolutely not. And what Apple's product does is it makes encryption easy by default. And so it means, as I said, the secretary to the Chair of the Federal Reserve, the HVAC employee, the chief of staff in your office--of course, your office should be protected anyway, but the regular person using a phone has the phone secured.    If Congress were to pass a law prohibiting use of encryption on Apple phones or however--you know, you wouldn't say it just for Apple, what it would do is it would weaken us, but not change it for the bad guys.    Ms. Landau. That's--if someone purchased a foreign phone, somebody can just download the app from abroad. They don't have to buy a foreign phone. They can just download the app from anywhere.    Ms. Landau. No. I mean, you would have to start inspecting so much as it comes over the Internet that it becomes an intrusive----    Ms. Landau. That's right. And we were there 20 years ago, which the open-source issue was part of the reason for the U.S. Government's change in export controls, which is part of what enabled----    Ms. Landau. Right. And what you get instead is over the last 20 years, the NSA has increasingly supported the secure technologies for private sector communications infrastructure, including the 256-bit algorithm.    Ms. Landau. That's exactly right.    Ms. Landau. I don't study shredding companies, but I'd be very surprised if there were.    Ms. Landau. Keys under Doormats.    Ms. Landau. It's wrong, and it's just, as Mr. Sewell said, once they've built that software, that software works for other phones. Of course, it has to have the serial number of the particular phone, so Apple has to sign--you know, has to take the software, put in a new serial number, sign it so the new phone accepts it. And that's where all the security risks comes in, because it becomes a routine process, and as I mentioned during my remarks, routine processes get subverted.    Ms. Landau. So there are two answers to that. If you're asking me a lawyer question, then I'm not a lawyer and I'll dodge; but if you're asking me as a technologist, then I would say that it is a security mistake. It's a security mistake because that code----    Ms. Landau. That's right. And it will be the target of organized crime and nation states, because it will be very valuable for somebody who puts a phone down as they go through Customs, for somebody who goes to a business meeting, and they're not allowed to bring their phone in because it's a meeting under nondisclosure, and the phone is sitting outside for a few hours. All sorts of situations. The phone will become very interesting. And if there's code that can actually get into the phone and get the data, that code is going to be the target of nation states----    Ms. Landau. That's right.    Ms. Landau. I'm not answering the legal question. I'm answering the security question. The security question, it makes a real mistake.    Ms. Landau. I'd like to just add a couple of comments. This is not about a new right of privacy; it's about a new form of security. And if we think about how the phones are used and increasingly how the phones are used, I certainly have two-factor authentication I use through my phone, but there are ways of using the phones as the original authentication device.    And if you make the phone itself insecure, which is what is being asked for by law enforcement, you preclude that, and that is the best way to prevent stealing of log-in credentials, the use of the phone as authenticator.    In terms of the risk of the disk and so on, it's not the risk of the disk going out because the disk is tied to a particular phone. The risk is that somebody will come into Apple and provide a rogue certificate that, you know, they're from law enforcement or wherever and will get the ability to decrypt a phone that should not be decrypted, whether it's the Chinese Government, or an organized crime group or whatever. That's the risk we're facing.    Ms. Landau. Absolutely not.    Ms. Landau. Extremely vulnerable. David Sanger's article in today's New York Times about the Ukraine power grid says that they got in, as I mentioned earlier, through the log-in credentials. It's based on a DHS memorandum that talks about locking down various systems.    I served for a number of years on NIST Information Security and Advisory--Security and Privacy Advisory Board, and we used to talk to people from the power grid and they would say, oh, it's okay. We're not--our systems aren't connected to the Internet. Well, they were fully connected.    We are--whether you're talking about the power grid, the water supply, whatever--we're connected in all sorts of the disastrously unsafe ways. And as I mentioned earlier, the best way to get at those systems is through log-in credentials.    Phones are going to provide the best way to secure ourselves. And so this is not just about personal safety of the data that all of you have on your phone, and it's not just about the location of where your family is, and it's not just about the business credentials, but it's really about the, as you say, Congressman Lofgren, it's really about the way we are going to secure ourselves in the future.    And what law enforcement is asking for is going to preclude those strong security solutions. It also is very much a 20th century way of looking at a 21st century problem. And I didn't get a chance to answer Congressman Gowdy, but the FBI, although it has excellent people, it hasn't put in the investment.    So Director Comey said--we talked to everyone who will talk to us, but I was at a meeting--I briefed at FCC a couple of years ago, and some senior people from DOJ were there. And I said, well, you know, NSA has scale X and scale Y, and DOJ said they won't share it with the FBI, except in exceptional circumstances, they keep it for themselves.    We're in this situation where I think law enforcement needs to really develop those skills up by themselves. And you ask about what it is this Committee can do, it's thinking about the right way for law enforcement to develop those capabilities, the right level of funding. The funding is well below what it should be, but they also don't have the skills.    Ms. Landau. I--can I just say something for a second?    Ms. Landau. I just wanted to add that in security, we have an arms race. People build good products, somebody finds a vulnerability. It could be the FBI, it could be--now, the FBI may not tell anybody about the vulnerability, but we have this arms race where as soon as somebody finds a problem, the next role of technology comes out, and that's the way we do things.    Ms. Landau. I think that the FBI should be developing the skills and capabilities to do those kinds of investigations. I think it's absolutely crucial. And I think that they have some expertise, but it's not at the level that they ought to have. And I think we're having this conversation exactly because they are--they are really using techniques from--they're using a mind-set from long ago, from 20 years ago, rather than the present.    Ms. Landau. Well, I certainly----    Ms. Landau. Of course. Thank you.    Ms. Landau. I've worked for two Silicon Valley companies, Sun Microsystems and Google, and that's certainly not what I saw at either one of them.    Ms. Landau. Well, here you're in a situation where the companies often want to collect the data. So, for example, if you're using smart meters, the company wants the data, the electric company wants the data to be able to tell your dishwasher, no, don't turn on at 4 in the afternoon when air conditioning requirements are high in Silicon Valley right now, turn it on at 8 at night or 2 a.m. And so, in fact, it actually wants the individualized data. And if it has the individualized data, then it can certainly share it with law enforcement under court order.    The security by design is often in the Internet of things securing data on the device and securing the transmission of the data elsewhere.    The issue in the Apple phone is that the data stays on the device, and that's the conflict that we're having. For the Internet of things, it's most useful if the data goes off the device to somewhere else where it can be used in a certain way.    Ms. Landau. So what we really have here over the last 20 years, as I mentioned earlier, is you see the NSA, and Snowden revelations aside, we don't have time for me to describe all of the subtle points there, but you really see the NSA working to secure private sector telecommunications infrastructure, many, many examples.    We have moved to a world of electronic devices, you talk about the Internet of things, that leak all sorts of data. And in order to protect ourselves, whether ourselves, our health data, our bank data, the locations of our children and so on, we need encryption and so on. But if you think more broadly about the risks that our nation faces and the risks of people coming in and attacking the power grid, people coming in and stealing data from whatever company, and stealing patented information and so on, you see a massive national security risk. And you've been hearing it from General Keith Alexander, we've been hearing it from Hayden, we've been hearing it from Mike McConnell, we've been hearing it from Chertoff, all the people who have been involved on the DHS and NSA side.    The only thing that can secure that is security everywhere, and the move that Apple makes to secure the phones is one of the many steps we need in that direction.    Ms. Landau. That's right. So I noticed that when Director Comey answered the question, he said: We talked to everyone who will talk with us.    And I, as I mentioned earlier, I don't know if you were here at that point, I had a conversation with some senior DOJ people a few years ago about using NSA tools in law enforcement cases, and they said: NSA is very loathe to share, because of course, when you share a tool, it can get into a court case, and then the tool is exposed.    And so I don't know in the ``we talked with everyone who will talk with us'' how much NSA revealed about what they know and what they can do, so that's the first place I would ask. Now, I phrased that incorrectly. That's the first place that I suspect has some tools for exactly this problem. But, yes, there were discussions last week in Silicon Valley. There have been discussions I've had with colleagues where people believe, as Congressman Issa portrayed various potential solutions, that there are ways to break into the phone.    There is, of course, a risk that the data might be destroyed, but I have described both in my testimony--written and verbal testimony, the FBI has not tried to develop this level of expertise and they should.    Ms. Landau. That's right. I don't think actually there needs to be more authority, but there needs to be a completely different view of how it's done. There probably needs to be some authority in terms of how do you handle it for State and local, because State and local will not have the resources, and so there has to be some sort of sharing of tools. And that's a jurisdictional issue and also just a--you know what, an issue between bureaucracies that will have to be worked out, and that will have to be worked out through law and policy.    But in terms of creating new authority, the FBI already has that authority, but it uses it at a much lower level, and I'm sure it's funded at a much lower level. They need to move from the situation they're in to dealing with 21st century technologies in the appropriate way.