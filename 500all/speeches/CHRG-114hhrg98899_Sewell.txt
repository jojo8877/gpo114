    Mr. Sewell. Thank you very much, Mr. Chairman. Thank you Members of the Committee and Ranking Member.    Mr. Sewell. Thank you for that technology hint.    Thank you, Mr. Chairman. It's my pleasure to appear before you and the Committee today on behalf of Apple. We appreciate your invitation and the opportunity to be part of the discussion of this important issue, which centers on the civil liberties that are at the foundation of our country.    I want to repeat something that we've said since the beginning, that the victims and the families of the San Bernardino attacks have our deepest sympathies. We strongly agree that justice should be served. And Apple has no sympathy for terrorists.    We have the utmost respect for law enforcement and share their goal of creating a safer world. We have a team of dedicated professionals that are on call 24 hours a day, 7 days a week, 365 days a year, to assist law enforcement.    When the FBI came to us in the immediate aftermath of the San Bernardino attacks, we gave them all the information we had related to their investigation. And we went beyond that by making Apple engineers available to advise the FBI on a number of investigative alternatives, but now we find ourselves at the center of a very extraordinary circumstance.    The FBI has asked the court to order us to give them something that we don't have, to create an operating system that does not exist. The reason it doesn't exist is because it would be too dangerous. They are asking for a backdoor into the iPhone: specifically, to build a software tool that can break the encryption system which protects personal information on every iPhone.    As we have told them and as we have told the American public, building that software tool would not affect just one iPhone. It would weaken the security for all of them. In fact, just last week, Director Comey agreed, and I think we heard the same here today, that the FBI would likely use this as precedent for other cases involving other phones. We've heard from District Attorney Vance, who's also said that he absolutely plans to use this tool on over 175 phones that he has in his possession. We can all agree this is not about access to one iPhone.    The FBI is asking Apple to weaken the security of our products. Hackers and cybercriminals could use this to wreak havoc on our privacy and personal safety. It would set a dangerous precedent for government intrusion into the privacy and safety of its citizens.    Hundreds of millions of law-abiding citizens trust Apple's products with the most intimate details of their daily lives: photos, private conversations, health data, financial accounts, and information about a user's location, and the location of that user's family and friends.    Some of you may have an iPhone in your pocket right now. And if you think about it, there's probably more information stored on that device than a thief could steal by breaking into your house. The only way we know to protect that data is through strong encryption.    Every day, over a trillion transactions occur safely over the Internet as the result of encrypted communications. These range from online banking and credit card transactions to the exchange of healthcare records, ideas that will change the world for the better, and communications between loved ones.    The U.S. Government has spent tens of millions of dollars through the Open Technology Fund and other U.S. Government programs to fund strong encryption. The Review Group on Intelligence and Communications Technology, convened by President Obama, urged the U.S. Government to fully support and not in any way subvert, weaken, or make vulnerable generally available commercial software.    Encryption is a good thing. We need it to keep people safe. We have been using it in our products for over a decade. As attacks on our customers' data become more sophisticated, the tools we need to use to defend against them need to get stronger too. Weakening encryption would only hurt consumers and well-meaning users who rely on companies like Apple to protect their personal information.    Today's hearing is entitled ``Balancing America's Security and Privacy.'' We believe we can and we must have both. Protecting our data with encryption and other methods preserves our privacy and keeps people safe.    The American people deserve an honest conversation around the important questions stemming from the FBI's current demand. Do we want to put a limit on the technology that protects our data and, therefore, our privacy and safety in the face of increasingly sophisticated cyber attacks? Should the FBI be allowed to stop Apple or any company from offering the American people the safest and most secure products it can make? Should the FBI have the right to compel a company to produce a product it doesn't already make to the FBI's exact specifications and for the FBI's use?    We believe that each of these questions deserves a healthy discussion, and any decision should only be made after a thoughtful and honest consideration of the facts. Most importantly, the decision should be made by you and your colleagues as Representatives of the people rather than through warrant requests based on a 220-year-old statute. As Judge Orenstein concluded yesterday, granting the FBI's request would thoroughly undermine fundamental principles of the Constitution.    At Apple, we are ready to have this conversation. The feedback and support we're hearing indicate to us that the American people are too. We feel strongly that our customers, their families, their friends, and their neighbors will be better protected from thieves and terrorists if we can offer the best protections for their data; at the same time, our freedoms and liberties we all cherish will be more secure.    Thank you for your time, and I look forward to your questions.    Mr. Sewell. It's by no means a fair contrast, Mr. Chairman. I've heard this raised before. It was raised in New York. It's been raised in San Bernardino, and every time I hear this, my blood boils.    This is not a marketing issue. That's a way of demeaning the other side of the argument. We don't put up billboards that talk about our security. We don't take out ads that market our encryption.    We're doing this because we think that protecting the security and the privacy of hundreds of millions of iPhone users is the right thing to do. That's the reason that we're doing this. And to say that it's a marketing ploy or that it's somehow about PR really, really diminishes what should be a very serious conversation involving this Congress, the stakeholders, the American people.    Just with respect to the New York case, Judge Orenstein last night took on this issue head-on, and he said, in footnote 14 on page 40, he said: I reject the government's claim. I find Apple's activities and the position that they are taking conscientious and not with respect to PR or marketing.    Mr. Sewell. So it's important to understand that we haven't started on a path of changing our technology. We haven't suddenly come to the notion that encryption security and privacy are important.    At Apple, this began back in 2009 with our encryption of FaceTime and iMessage. We've been on a path from generation to generation as the software and the hardware allow us to provide greater security and greater safety and privacy to our customers.    What happened between iOS 7 and iOS 8 was that we were able to transform the encryption algorithm that is used within the software and the hardware of the phone to provide a more secure solution.    Mr. Sewell. I think it's a combination of things. From our perspective at Apple, it's because we see ourselves as being in an arms race, in an arms race with criminals, cyberterrorists, hackers. We're trying to provide a safe and secure place for the users of our devices to be assured that their information cannot be accessed, cannot be hacked or stolen. So, from our perspective, end-to-end encryption move is an effort to improve the safety and security of our phones. From the terrorist's perspective, I think it's an effort to communicate in ways that cannot be detected, but the terrorists are doing this independently of the issues that we're discussing here today.    Mr. Sewell. Well, we could show you how to do that.    Mr. Sewell. That's absolutely right, Mr. Chairman. One of the most pernicious apps that we see in the terrorist space is something called Telegraph. Telegraph is an app that can reside on any phone. It has nothing to do with Apple. It can be loaded either over the Internet or it could be loaded outside of the country. And this is a method of providing absolutely uncrackable communications.    If what happens here is that Apple is forced to write a new operating system, to degrade the safety and security in phones belonging to tens or hundreds of millions of innocent people, it will weaken our safety and security, but it will not affect the terrorists in the least.    Mr. Sewell. Thank you, Ranking Member.    Functionally, there is no difference. What we're talking about is an operating system in which the passcode is an inherent and integrated part of the encryption algorithm. If you can get access to the passcode, it will affect the decryption process itself.    What we're being asked to do in California is to develop a tool, a tool which does not exist at this time, that would facilitate and enable the FBI, in a very simple process, to obtain access to the passcode. That passcode is the cryptographic key. So essentially, we are throwing open the doors, and we are allowing the very act of decryption to take place.    Mr. Sewell. It's absolutely false. As I said in my opening statement, we care deeply about the same motivations that motivate law enforcement. The relationship with law enforcement falls within my shop at Apple. The people that we have who assist law enforcement every day are part of my team, and I'm incredibly proud of the work they do.    We have dedicated individuals who are available around the clock to participate instantly when we get a call. As we've discussed a little bit earlier in Director Comey's testimony----    Mr. Sewell. All right. I'll try to be very quick. We do everything we can to assist law enforcement, and we have a dedicated team of people who are available 24/7 to do that.    Mr. Sewell. This is not about the San Bernardino case. This is about the safety and security of every iPhone that is in use today.    And I'd like to address one thing that Director Comey raised. This is--there's no distinction between a 5C and a 6 in this context. The tool that we're being asked to create will work on any iPhone that is in use today. It is extensible; it is common; the principles are the same. So the notion that this is somehow only about opening one lock or that there's some category of locks that can't be opened with the tool that they are asking us to create is a misnomer. It's something that we needed to clarify.    Mr. Sewell. Congressman, I think that, ultimately, Congress must decide this issue. So I'm completely in support of the position that you're articulating.    I think we find ourselves in an odd situation in a court in California, because the FBI chose to pursue, in an ex parte fashion, a warrant that would compel Apple to do something. We view that not as an extension of the debate, not as a way to resolve this issue; we view that as a way to cut off the debate. If the court were to grant the relief that the FBI is seeking, we would be forced to do the very thing which we think is at issue and should be decided by the American people. We'd be forced to create the tool.    Mr. Sewell. I do not have a bill for you to consider.    Mr. Sewell. What we're asking for, Congressman, is a debate on this. I don't have a proposal. I don't have a solution for it. But what I think we need to do is to give this an appropriate and fair hearing at this body, which exists to convene and deliberate and decide issues of legislative importance.    We think that the problem here is we need to get the right stakeholders in the room. This is not a security-versus-privacy issue. This is a security-versus-security issue, and that balance should be struck, we think, by the Congress.    Mr. Sewell. Congress, we will follow the law that comes out of this process. We certainly understand.    Mr. Sewell. Congressman, I do think we have said what we stand for and what we believe is the positive place.    Mr. Sewell. Absolutely none, Congressman.    Mr. Sewell. Right. Good question, Congressman. And bear in mind that what we're being asked to do is write a brand new computer code, write a new operating system. The law, with respect to the applicability of computer code to speech, I think, is well established. So this is a compelled speech by the government for the purpose of the government.    Mr. Sewell. Which is absolutely a First Amendment problem. And bear in mind, this is a speech which Apple does not want to make. This is our position.    On the Fifth Amendment, the issue is conscription. The issue is forced activity, forced labor.    Mr. Sewell. Congressman, I'm not aware of it. The steel cases during the war were the ones that were most applicable.    Mr. Sewell. We do, yes, indeed.    Mr. Sewell. No, we don't. We wish we did.    Mr. Sewell. I believe so. We don't know what the condition of the phone is and we don't know what the condition of the RAM is, but yes.    Mr. Sewell. We've never been asked for our source code.    Mr. Sewell. That's absolutely correct, yes, Congresswoman.    Mr. Sewell. That's correct.    Mr. Sewell. Let me----    Mr. Sewell. Sure.    Mr. Sewell. The best analogy that I can come up with, and I've been struggling with how do we create the right kind of analogy for this situation. If Apple had a box somewhere that we could guarantee, we could assure 100 percent certainty, that anything that was put in that box was not susceptible to thievery, to attack, to corruption; if we had such a place in the world, we wouldn't be here today----    Mr. Sewell . Because what we would have done is gone to our customers and we would have said, give us your passwords. We can absolutely 100 percent protect them. And then if you lose your phone, if you need our help, we can just give you the passcode.    Mr. Sewell. Exactly right. And now the bizarre situation is that essentially, the FBI is saying, We all realize it's silly that everybody would give you your password, but instead, we want you to build a tool that will get those passwords, and we're telling you, you can put that tool in this box that doesn't exist.    Mr. Sewell. We could write a program that would suppress that protective measure.    Mr. Sewell. Right. We're being asked to do three things, but it is capable--we are capable of doing those three things. The issue is what's the consequence of doing those?    Mr. Sewell. Absolutely.    Mr. Sewell. Yes, actually, in the iOS 8 and 9 generation, we have encrypted the iCloud data. It's encrypted in a different way than it was before and we think in a more secure way.    Mr. Sewell. It is encrypted in a different way----    Mr. Sewell. Yes.    Mr. Sewell. With respect to the phone itself, we believe the encryption we provided in iOS 8 makes that effectively impossible. With respect to the things that are going on at the Internet level, there are very sophisticated techniques that can be used by malicious actors who have access to the Internet itself. There are ways to fool the Internet into thinking that something is what it isn't. And so I think there is a vulnerability still in that regard. But on the phone, what we've tried to do is to remove that possibility with iOS 8 and 9.    Mr. Sewell. I did, that's correct.    Mr. Sewell. The Fifth Amendment issue derives from the fact that we're being asked to write code, and code is speech, and Supreme Court has held that that speech is protectable. So we're being asked to speak by the government. That speech is not speech that we want to make. And the First Amendment provides us with protections against being compelled to speak by the government. So that would be the First Amendment argument in a nutshell.    The Fifth Amendment provides us with protection from conscription, protection from being forced into labor at the government's will, except under the most extraordinary of circumstances, which I discussed with Congressman Issa. But that's the Fifth Amendment issue.    Mr. Sewell. Well, there are a number of parts of that question, Congressman, so thank you. The way that this would affect Apple is that it would affect our customers. It would affect everyone who owns an iPhone, and it would create a risk for everyone who owns a phone that their data could be compromised, that their security could be compromised.    With respect to the international question, I agree with you. I think America should be leading on this issue. And I think that the world is watching what happens right now in our government and what happens, even today, with respect to this particular debate.    Our ability to maintain a consistent position around the world, our ability to say that we will not compromise the safety and security of any of our users anywhere in the world is substantially weakened if we are forced to make that compromise here in our own country. So I urge this Congress, and I urge the government generally to understand that to take a leadership role, give us the strong support that we need to resist any effort by other governments to weaken security and privacy.    Mr. Sewell. I think that is certainly one possibility, yes, sir.    Mr. Sewell. Absolutely. There's nothing that would preclude it from being used on any iPhone that is in use today.    Mr. Sewell. So to date, we have not had demands like that from any other country. The only place that we're having this debate is in our own country. But as I said before, I think if we are ordered to do this, it will be a hot minute before we get those requests from other places.    Mr. Sewell. I would agree that if we're forced to create this tool, that it reduces the safety and security not within our systems, Congressman, but with our users.    Mr. Sewell. Congressman, that's what----    Mr. Sewell. That's what makes this such a hard issue, because we're balancing two different but very similar issues: private security, the security of people who use iPhones, the location of your children, the ability to prevent your children from being kidnapped or harmed, versus the security that's inherent in being able to solve crimes.    So it's about how do we balance these security needs, how do we develop the best security for the United States. If you read the statements by General--any of the encryption specialists today, we'll say that de-featuring or debilitating encryption makes our society less safe overall. And so that's what we're balancing. Is it the right thing to make our society overall less safe in order to solve crime? That's the issue that we're wrestling with.    Mr. Sewell. Congressman, we will follow the law. If we're ordered to do this----    Mr. Sewell. Congressman, what I said was we have to balance what is the best security for the country. Not balance when we should give law enforcement what they're asking, but balance what's the best security for the country.    Mr. Sewell. Congressman, what I said was privacy, security, personal safety.    Mr. Sewell. Where we would create a tool that doesn't exist----    Mr. Sewell . In order to reduce the security and safety of our users?    Mr. Sewell. I'm not aware of such a fact pattern.    Mr. Sewell. No, I've said that we will follow the law. If a balance that is struck, if there is an order for us to comply with, we----    Mr. Sewell. That order is being challenged at the moment as we speak. There's an order in New York that says----    Mr. Sewell. We don't have legislation to propose today, Congressman. What we've suggested----    Mr. Sewell. Congressman, where we get to the point where it's appropriate for us to propose legislation, not just Apple, but the other stakeholders that are engaged in this process, I'm sure there will be legislation for Congress to consider.    Mr. Sewell. I don't have an answer for you today. No one's had an answer for you today.    Mr. Sewell. It is my firm belief that such legislation can be drafted. I do not have language for you today.    Mr. Sewell. Congressman, we're willing to and we've offered to engage in that process.    Mr. Sewell. Both, of course.    Mr. Sewell. If, after we have the debate to determine what the right balance is, then I think that's a natural outcome.    Mr. Sewell. I can't anticipate that, Congressman.    Mr. Sewell. I'm sorry. Is that a case, Congressman?    Mr. Sewell. Congressman, we've made an argument, a constitutional argument. If the courts determine that that argument isn't firm, then we will lose the argument.    Mr. Sewell. You've given me two examples that I've not heard of before.    Mr. Sewell. I'm not familiar with these cases. But this is what the court will decide.    Mr. Sewell. I look forward to the cases.    Mr. Sewell. I absolutely can. Thank you, Congressman.    First, I agree with you that this is not a problem which--there are people that are trying to break into these systems. There are people who are trying to steal this information, if it existed. And their capabilities are increasing every day. So this is not a threat which is static. This is a threat which is increasing.    The three parts that we're being asked to develop are, first, a method to suppress the data deletion after 10 failed attempts. The second thing that we're being asked to suppress is the time delay between successive attempts. Both of these are specifically tailored to deal with the situation where your phone is stolen, or some bad person is trying to break into it, and it's specifically designed to defeat the brute force attack.    The third piece is interesting, because the third piece is the government asking for us to rewrite the code that controls the touch screen, and allow them to put a probe into the phone and to bypass the need to enter numeric digits through the touch screen. The only reason that that makes sense, Congressman, is if you anticipate that this is going to be technology used on other phones, and other phones that likely have more complicated passcodes.    Mr. Sewell. That is incorrect.    Mr. Sewell. Unquestionably, Congressman, and that's exactly the risk and the danger that we foresee.    With respect to the comment that Mr. Vance just made, in fact, the request that we got from the government in this case was that we should take this tool and piece--put it on a hard drive, and send the hard drive to the FBI. The FBI would then load that hard drive into a computer, hook the phone up to the computer, and they would perform the entire operation. So that this whole tool is transportable on a hard drive. So this is a very real possibility.    Mr. Sewell. Thank you, Congressman. And I absolutely--I agree with what you said. And I think that--I am proud to work for Apple. And I think Apple embodies so many of the most valuable characteristics that make up America, make America a great place. We stand for innovation, we stand for entrepreneurship, we stand for empathy, we stand for all boats rise. And so I am very proud. And we are an American company, and we're very, very proud of that.    The point about security outside the United States is exactly the point that drives us. We are on the path to try to create the very best, most secure, and most private phones that we can. That's a path that will probably never end, because the people that we're competing with, the bad guys, not just in the United States, but all over the world, are on an equally aggressive path to defeat everything that we've put into the phone. So we will continue from generation to generation to improve the technology, to provide our users with a safer experience.    Mr. Sewell. Without involving Apple, without having Apple----    Mr. Sewell. - complicit in that. I don't think we have a position to object or not object to that. I think if the FBI has a method to brute force a phone, we have no ability to stop them.    Mr. Sewell. Well, I think that privacy and security are vitally important national interests. I think that if you weaken the encryption on the phone, then you compromise those vitally important interests.    Mr. Sewell. Then I'm sorry. Perhaps I'm misunderstanding. If the FBI had the ability to brute force a phone, I would suggest that that's a security vulnerability in the phone. So I would have a problem with it, yes.    Mr. Sewell. We don't. And I'm glad that you asked about the Mills case, because I think it's instructive about the way that we do work together cooperatively. I know that we met with members of your staff----    Mr. Sewell. Congressman, let me be clear. We have not said that we cannot create the tool that the FBI has asked us to create.    Mr. Sewell. Short of creating something new, no.    Mr. Sewell. The first thing we would do is to try to look at all of the data that surrounds that phone. There is an enormous change in the landscape over the last 25 years with respect to what law enforcement has access to. So when we have an emergency situation like that, whether it be a lost child or the airplane--when the Malaysia airline went down, within 1 hour of that plane being declared missing, we had Apple operators cooperating with telephone providers all over the world, with the airlines, and with local law--well, the FBI, to try to find a ping, to try to find some way that we could locate where that plane was. So the very first thing that we would do in the situation is to bring to bear all of the emergency procedures that we have available at Apple to try to find them.    Mr. Sewell. I appreciate that, Mr. Congressman.    Mr. Sewell. I absolutely do. I do not subscribe to the position articulated by Director Comey.    Mr. Sewell. I think that's absolutely true. Somewhat ironically, I suppose, we have the FTC at this point actively policing the way in which technology companies deal with these issues, and we can be liable under the--Section 5 or under the authority of the FTC if we fail to close a known vulnerability.    Mr. Sewell. You are.    Mr. Sewell. That is correct.    Mr. Sewell. Your data is not stored in that cloud.    Mr. Sewell. There are a number of things that are in the cloud, so I should probably be clear about what's there.    Mr. Sewell. With respect to personal data, no personal data is there unless the individual's data--the individual himself has registered as having a Chinese address and having a Chinese access point. In addition, we have other data, which has to do with film content, movies, books, iTunes music. The reason we do that is because of something called latency. If you're streaming across the Internet, and you have to bring the data from the United States to China, there's a lag time, there's a latency piece, whereas if we move that data closer to China, either Hong Kong or mainland China, then we can provide a much better service to our customers.    Mr. Sewell. Sorry. Did you say in time?    Mr. Sewell. So the time--the cost is building the facilities. I don't have a number for that. It's certainly not something that I am aware of, although, of course, the company has that information. In terms of the time, once--once the server exists, once there is a receptacle for the data, in theory, it's instantaneous.    Mr. Sewell. I think it means that we have put our privacy at risk. The tool that we're being asked to prepare is something which could be used to defeat both the safety and the privacy aspects of----    Mr. Sewell. Short of creating the tool that they have asked us----    Mr. Sewell . We are not aware of such a method, no.    Mr. Sewell. Congressman, to be fair, we haven't claimed that the time that it would take to create the tool is the undue burden. Our claim is that the undue burden is to compromise the safety and security of all of our customers.    Mr. Sewell. Congressman, the answer is very simple. We don't believe this is a one-phone issue. We don't believe that it can be contained to one phone or that it would be contained to one phone.    Mr. Sewell. That's correct. For over 75 days, we've been working with the FBI to try to get to more information to try to help solve this crime.    Mr. Sewell. That's right. In fact, the call came in to us at 2:47 a.m. On a Saturday morning. We have a hotline that exists; we have people who are manning that hotline.    Mr. Sewell. By 2:48 that morning, we were working on the case, and we responded by giving the FBI all of the information that we could immediately pull from our sources, and then we continued to respond to subpoenas and to work directly with the FBI on a daily basis.    Mr. Sewell. That's correct.    Mr. Sewell. We did comply with that and subsequent requests.    Mr. Sewell. That's right. And it's important that in the intervening stage, we had actually sent engineers to work directly with FBI technicians in Washington, D.C., and in Cupertino, and we provided a set of alternatives, or options that we thought should be tried by the FBI to see if there might be some possibility that we could get into this phone without having to do the tool that we're now being asked to create.    Mr. Sewell. We're being asked to create a method to hack our own phones.    Mr. Sewell. Thank you for the question, Congressman. We have and spend a lot of time thinking about how we can assist our customers in the event that they have a problem, if they have lost a phone, if they have--they're in a situation where they're trying to recover data. We have a number of mechanisms to do that, and we will continue to improve those mechanisms as we move forward.    It's very important to us that we try to think about the consequences of the devices that we create. In this particular case, the passcode unlock is not something that we think lends itself to a small usage. The problem with this particular issue is that once you take that step, once you create the mechanism to unlock the phone, then you have created a back door, and we cannot think of a way to create a back door that can only be used beneficially and not be used by bad people.    Mr. Sewell. And we have provided information in this case. We have provided logs. We have provided iCloud backup. We've provided all the things that we have that are available at our disposal.    Mr. Sewell. Certainly. One of the methods that we might enable the phone in San Bernardino to do what's called an auto backup. That is, the issue that the FBI is struggling with is to find data between a certain timeframe, the time of the last backup and the time of the horrific incident in San Bernardino.    If the phone would backup, that evidence, that information would become available to the FBI. The way that we can back these phones up in an automatic way is we connect them to a known WiFi source, a source that the phone has already connected to before and recognizes. If you plug the phone in and you connect it to a known WiFi source, it will, in certain circumstances, auto backup, and so the very information that the FBI is seeking would have been available, and we could have pulled it down from the cloud.    By changing the password--this is different than passcode--but by changing the password, it was no longer possible for that phone to auto backup.    Mr. Sewell. Let me be clear about the question. The Chinese, undoubtedly, have the ability to access their own cloud.    Mr. Sewell. But with respect to the U.S. cloud, we believe that--again, I'm struggling because of the words. The cloud is a synonym for the Internet.    Mr. Sewell. So, of course, Chinese people have access to the Internet. Are we aware of a Chinese hack through Apple? No. But beyond that, I can't say.