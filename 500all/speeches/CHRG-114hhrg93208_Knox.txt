    Ms. Knox. Thank you, Chairman Rokita, Ranking Member Fudge, and members of the subcommittee for inviting me to testify today. My name is Allyson Knox. For 10 years I worked in the fields of education, workforce development, and economic development at the local, regional, and state levels in Michigan. I have worked at Microsoft for 10 years, and currently serve as the director of education policy. I am pleased to be here today to discuss this important issue of student privacy.    Microsoft believes students must be protected. Student data belongs to students and their parents. And students are not commodities to be monetized through advertising. Over the past year, revelations of government surveillance, highly-publicized data breaches, and other stories of personal data being used inappropriately have dominated the media. Microsoft, a provider of education technology, continues to balance education objectives, as well as privacy and safety expectations.    For many years, schools have been increasing the use of technology in the classroom because it transforms education. It enables personalized instruction, and it helps students learn. Schools that use cloud-based services rather than maintaining and updating their own on-site servers, they save money and can access the latest technology. Cloud computing allows teachers and students to access their documents and communications, such as email, anywhere from almost any device, enabling learning any time and anywhere.    We have seen great changes on the technology side. But the primary federal law focused on protecting student privacy, the Family Educational Rights and Privacy Act, or FERPA passed in 1974 has not kept pace with these changes.    Think back to a classroom in 1974. I think we can all remember student data being collected and stored in an old-fashioned way on paper forms sent home with kids and stored in school filing cabinets.    The world of information storage and sharing has certainly changed. In almost all schools, information about a student is stored digitally, and it can be accessed through the school's internet or the open internet. The data is portable and often not deleted when the student graduates from high school.    There are obvious difficulties with the law that is 4 decades old. And there are three areas to consider. First, it is questionable whether FERPA covers email stored in a cloud. As a result, some interpretations are that FERPA applies to cloud-based email for faculty, but not for students, and that FERPA doesn't apply to most third-party online courses. FERPA would benefit from an update to reflect these new types of technologies.    Second, FERPA was written to apply only to educational institutions. It should be updated to prohibit third parties from using data for targeted advertising or for building profiles to advertise to students after they leave school.    And third, FERPA's primary sanction is the denial of federal funds to school. This all-or-nothing enforcement penalty is so draconian that it has never been used. As a result, FERPA provides no real incentive for technology providers to improve data privacy practices. The time has come to do the difficult work of revising this law to bring it to the 21st Century.    And in the absence of federal action to update FERPA, states have taken this issue into their own hands. This year, already over 100 student privacy bills have been introduced in 32 states. It is becoming more and more difficult to interpret and comply with the patchwork of federal and state laws on this issue, even for a company of our size.    Microsoft and other technology companies have also moved forward on their own to set a higher standard for protecting student data. Last October, Microsoft was one of the 14 original signatories of a detailed and voluntary industry pledge, led by Representatives Messer and Polis, about how to protect student privacy. Today, the pledge has over 100 signatories.    Under the student privacy pledge, school service providers promised to not sell student information, not target advertise to students, use data for authorized education purposes only; and there are 5 other points, but I am running out of time. The pledge has been influential and beneficial, but Microsoft believes that signing it is only part of what must be done to help inform schools and parents on how to protect student data. It is for this reason that Microsoft has worked closely with key lawmakers and national education associations to help inform and educate stakeholders about the student privacy issue.    Again, I thank you for this opportunity to come before you today to discuss these important issues, and I look forward to answering any questions.    Ms. Knox. Sure, sure. I think starting with a commitment to trust is important. I know that at our company, we have principles and policies in place about establishing trust with customers. So starting with a commitment is always important. And then, you know, knowing what it is you believe. For example, in our company, we believe that people own their own data; right? So the student and the parent--the student's data belongs to them. So being clear on those pieces sort of guide, then, action and belief.    So then how does that translate? At least, again, where I work, that translates into making sure that privacy is in the design of any product that we put on the product. So if we design a product, there is always a privacy expert with the product developer. That means you are baking it in to who it is and what it is you are going.    And then, you know, wherever we go, we try to be extremely transparent about the data. So I know that the question has to do with schools and there are all these different devices and how do you make sure that data stays secure. The cloud, you know, unites them, right, brings them all together. And it is a service of--in a remote data center, basically--and educating and becoming clear and being very transparent. Whoever that third-party provider is needs to articulate in the clearest terms how that data flows in and out, who has--if anyone have access.    And we have an entire center called the trust center. We have a trustworthy computing initiative. This morning I actually watched a couple of videos of some software engineers who took me on a virtual tour of our data centers. And I could see physical, you know, protections. I could see software protections. I could see a blue team and a red team identifying good and bad use. I mean, being transparent helps inform, but it also decreases fear. Because we believe data is critical in the age of 21st Century education, just like everybody else does.    And then two other points is, you know, in general, always committing, putting something in place where improvement continues. So whatever the law ends up doing--you know, whatever direction it goes in, there should be a piece in there that says we will constantly improve our practices based on the times and the opportunities that come available.    We do that at the company, as well. So that is, again, part of the way that we approach our work, the way that we, you know, commit to it, believe in it, act on it, create products. And I think that can be translated into the way that society sort of behaves when designing laws for students and their privacy.    Ms. Knox. So your question is how does student data end up in the hands of marketing people. If the students are using certain cloud infrastructures and it is held by a third party and that third party's contract terms aren't clear, it is possible for them to trend through the data that flows. So emails, forms that the school district is completing. I am sure Dr. Abshire may have some specific examples of maybe situations.    But when it is flowing through the data center, it is possible to, you know, take a peek at it and find trends and put it kind of on the market to other businesses who want to advertise to those students. And then certain targeted ads then would flow back to the students. And when again they are emailing, low and behold, what they were talking about maybe in an email 6 months ago, there is an advertisement for it.    So this idea of trust and understanding where the data is flowing and committing to not using data for noneducational purposes becomes critically important in this information.    Ms. Knox. I know--    Ms. Knox. Right. Oh, assuming--well, the existing penalty would be, you know, misleading. And if you actually do different activities than you said you would do in the pledge, then the FTC can fine you.    Ms. Knox. Right.    Ms. Knox. Yes.    Ms. Knox. Just really quickly, one of the things I really liked about Dr. Abshire's written and what you mentioned in your oral is she talked about not overburdening schools with more regulation. And I can't agree more. And I think that was part of the brilliance of the Student Privacy Pledge. And I just want to thank Representative Polis for his leadership there. The idea of industry standing up and raising our hand and taking a pledge and saying these are the kinds of things we think we should be doing and we will do them when it comes to students, I think it is important, and I think it does help with schools.    Ms. Knox. Right. But I think it could translate right into FERPA. I mean, not word for word. But the same principles. There could be a new piece of FERPA that developed that looks at third party or business--    Ms. Knox. Well, great for us we have some lead amazing products. And I feel lucky that I get to go out into classrooms and talk to actual teachers who use them. Office 365 being in the classroom. And these are specifically designed so that students don't receive any unwanted advertisement. And so they--a teacher can--as one teacher told me, no more in my classroom can anybody come back from doing their homework and say their dog ate their home work. Because everything is now stored in the cloud. And there is more productivity. Kids are really engaged. This office 365 product has really inspired him to do new things with technology; collect data, do analytics on which equation he is teaching about, you know, students struggled with the most at night and didn't struggle as much on this equation, so he changes his teaching strategy.    So all these things are great. But at the same time, we need to make sure that they are--that the student is protected and they are safe. And that is what these products do. It is possible to strike the balance that Dr. Abshire keeps talking about.    Ms. Knox. Just in terms of the confusion that parents may find. We hosted last month--or in December--approximately 30 state PTA leaders in our office. And we conducted a 2-day training on student privacy. Everything from personalized learning to what is cloud computing to--I mean, I can't--what is data-driven instruction.    But one of the most interesting moments, I think, for all of us was none of the adults had actually experienced personalized learning. And so they had never--I mean, those were words and terms. And so once they felt the power of oh, my gosh, I get to move on quicker based on the data because I am actually learning quicker than this person, but this person might come and help me, they got really excited once they experienced it.    But then they also thought where is all this data going? And then breaking down the cloud and how that works. And it was just a fascinating--I don't know if you want to mention--or comment. But it was good.    Ms. Knox. I mean, the way I think about the answer to that question is there is data that is collected in a classroom, right, that informs instruction. Then there is about classroom. Then there is data at the school level. Then there is data at the county level. And then it goes to the state.    And so you are right; there is all these different layers and there are policies that sort of try to blend together and weave together. I keep looking over at Dr. Abshire because she lives this. And so the answer to your question is it is like a fabric or a quilt that needs to kind of work all in the same direction. But there are many different buckets of data at play in the education system.    Ms. Knox. I mean, from my point of view, the personal data, why--I am very concerned. I don't want to see kids get viruses that penetrate their system. I don't want them to be--you know, to have data loss or have their passwords exposed. I don't want to have their data sold for inappropriate or un-educational purposes. All those types of things more on the micro or the personal level. But then data can being aggregated and there can--people can look for trends. And then there can be some unwanted advertising that is targeted towards the student or groups of students based on clicks and searches and ways they interact with the technology.    There are lots of ways for data to inform the technology that has been used. And sort of what does the company decide to do with the data that they are collecting? Is it for the purpose of improving the business, or is it actually to be monetized and sold and be making money off the whole process?    Ms. Knox. I mean, from the company--from Microsoft's point of view, we can operate as a third-party vendor. But our belief system, what we adhere to, our principles and policies, is your data that we are gonna put in a data center offsite, you own that data. We don't own that data, and we will not access it. And so we have that in our contract. And that is, I think, a way of addressing and--well, addressing the issue, but increasing trust among all these stakeholders who could access the function--    Ms. Knox. I think there are lots of ways probably to respond to that question. My big--my general response about the NAPE and the data that is collected, as a general education system as a country, we are trying to constantly improve it. So we are collecting, you know, aggregated data to make good, informed decisions so that we can improve our systems.    Ms. Knox. Sure. Sure. And I would be remiss not to also thank Representative Messer for your leadership on the Student Privacy Pledge. So thank you for that. I know you joined a little after Mr. Polis or Representative Polis.    The state bill. So the California bill was very constructive. We found it constructive for the larger conversation. I think the data that came out of 2014 where there were 106 student privacy bills introduced, I think 28 of them had to do specifically with protecting student privacy. And I think it came from, like, there were 32 different states. The numbers are even, you know, at that level and getting higher as we speak.    What is interesting is that there is such a different kind of mix of the state bills. So some of them are looking at governance. You know, how--we should have a security officer or a CIO or a student privacy leader at the state level, you know, setting up governance systems, versus sort of this idea of how companies should behave in relation to student privacy, and especially third-party vendors.    So I think the Student Privacy Pledge has really helped specify and clarify and bring the industry together to commit to the eight specific objectives of the pledge. And we have been able to say okay, we would like to take these commitments and make sure that the other state bills that are moving right now, we want to make sure that they kind of work in conjunction with each other.    Ms. Knox. It is very possible to strike a great balance between harnessing the power of personalized learning, while also safeguarding our students' data. Ask more from companies. There is no question that they need to be transparent, articulate clear contracts; that they need to make sure that they have comprehensive data security systems; and that they commit to not using data for noneducational advertising practices.    Ms. Knox. We would like it to be part of it. Yes.