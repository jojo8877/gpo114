    Dr. Sullivan. Chairwoman Walorski, Ranking Member McGovern, and other Members of the Subcommittee, thank you for inviting me to participate in today's hearing. I am talking to you today because the impact of social programs has been the focus of much of my academic research, and recently I co-founded the Wilson Sheehan Lab for Economic Opportunities, a research center at the University of Notre Dame that implements impact evaluations to identify innovative, effective, and scalable programs that help the disadvantaged move to self-sufficiency. We work with some of the largest private providers of services to the poor in the country, such as the Catholic Charities Network, as well as state and local agencies. While these front line providers are driven by compassion and motivation for helping the poor, most of them design and launch programs without solid evidence of effectiveness. The same could be said of many national programs, most of which are not evaluated, or are evaluated with unreliable methods.    One of the greatest advances in the social sciences in recent decades is the development and application of methods that allow us to determine whether social programs are having their intended effect. The gold standard of these approaches is the randomized controlled trial. Nowadays gathering evidence is commonplace in many sectors. The medical profession runs tens of thousands of experiments each year to test the effectiveness of new interventions. These experiments have led to vast improvements in health care all across the globe. Shouldn't the same commitment to proven effectiveness apply to our social programs? Using evidence to steer resources towards the most effective programs would allow us to do more good with the limited resources available.    Despite its size and importance, there is little hard evidence of the impact of SNAP. There is some promising quasi-experimental evidence showing that in utero exposure to the food stamp program is associated with increased birth weight and lower rates of obesity and heart disease in adulthood. But this evidence is for those exposed to food stamps in the late 1960s and early 1970s. There is a clear need for rigorous experimental evidence of the impact of SNAP in its current form.    Evaluating SNAP can be challenging, given its structure. It is much easier to conduct experiments when a program is rolled out, expanded, or changed in significant ways, or when the program is not made available to all those who might be eligible. SNAP is an entitlement program that has been around for more than 5 decades, and there has been relatively little experimentation with program rules. I applaud this Subcommittee's efforts to generate more evidence to guide the future of nutrition policy. There are a number of strategies that can help develop a strong base of evidence and improve policy. Let me highlight just a few.    First, policymakers should incentivize innovation. Programs can't be built on evidence of effectiveness if there is no evidence. The most innovative ideas for social programs frequently come from states and local providers, but they need funds to experiment with new ideas. The most recent farm bill made important strides towards encouraging innovation by authorizing $200 million to support pilot projects designed and implemented by state agencies to reduce SNAP dependency and encourage work. These grants create a pipeline of innovative programs that, if proven effective, can be scaled up to ensure broad impact.    Second, the program needs to be rigorously evaluated, otherwise there is no way to know whether the program is being implemented correctly, and having its intended effect. If a funding agency does require an evaluation, it often does not require the evaluation to employ the best experimental or quasi-experimental methods possible, which limits the extent to which this evidence can shape future policy.    Third, researchers need greater access to administrative data. Collecting survey data for an evaluation can be an expensive proposition. In many instances, administrative records already collect information on key outcomes, such as employment, earnings, program participation, and many others. But these data are often not available for evaluation purposes. Some cities and states have established administrative data repositories that can be used for evaluation, but there needs to be a national effort. The Ryan-Murray Act represents an excellent step towards greater access to data. This legislation would create a commission to study how administrative data might be compiled in order to facilitate research and evaluation. This would make possible countless studies of government programs, resulting in the design of more effective policies.    Advances in technology and data collection have greatly expanded opportunities to implement high quality evaluation of social programs. By encouraging innovation and evaluation, and by targeting support at interventions shown to be successful, policymakers will ensure that our social programs are more effective at helping vulnerable populations get ahead. We at the Wilson Sheehan Lab welcome this transformation in the way we fight poverty in America. Thank you.    Dr. Sullivan. Thank you for the question. I mentioned in my written testimony a number of challenges in evaluating the SNAP program broadly. These challenges arise because the program is an entitlement that is available universally, and so we lack a group to which we can compare the effects of the program. One might want to compare the effects of the food stamp program for participants to those that look like the participants, but don't participate. But eligible households, because it is an entitlement, are eligible to receive the benefits. So what this means is that we are limited in the kinds of rigorous studies that we can do of the food stamp program. One of the easy ways to address that would be to run pilot projects that we can evaluate in an experimental way, and that is the kind of things that have been done, and encouraged, and funded by the most recent farm bill.    So pilot projects are a nice way to test additional features. Unfortunately, they are limited in terms of the ability to test the overall program. If I wanted to test the overall program, I would rewind the clock to 1964, when we were first rolling this out, and roll it out gradually, and construct a rigorous research design around that rollout. But, unfortunately, I can't roll back the clock, so we can't do that.    The Chairwoman. And this Committee has been consistent from the start that we believe in SNAP.    Dr. Sullivan. Yes.    The Chairwoman. We are not looking at tearing apart a program. We are looking at the areas where we make this work better, and some of the things that all of you have talked about today. Do you believe there is space within the program to do an evaluation?    Dr. Sullivan. The current program? I mean, absolutely, and I think that the idea of pilots is a great place to start, right, because you can allow the innovators, those at the local level, to experiment with new ideas, and test them rigorously to find out what works and what doesn't amongst these new ideas. And then once you start with a pilot, and you build a body of evidence on what works, you can scale those effective programs up, and you can run a larger demonstration project. And then you evaluate it again.    And once you build the evidence on the effectiveness of a demonstration project, now let us scale it up to a larger level. Maybe it becomes state waivers. Or, another way to test this on a broad scale, there will be much broader support for those kinds of initiatives if they are built off of evidence at the local level that these kinds of changes really work.    The Chairwoman. I appreciate it. Mr. Everett, your work extends well beyond SNAP to actually address hunger in Texas. Can you talk a little bit about what it is you are researching and evaluating?    Dr. Sullivan. I would agree that it would be wonderful to study what the impact of food stamp generosity is on the well-being of recipients. And Mr. Weill mentioned a natural experiment was, when we expanded the generosity in 2009 temporarily. And the challenge is what kind of evidence can we collect when we do those kinds of things? We expanded food stamp generosity at the same time that a lot of other things were going on in the macroeconomy that made it difficult for low-income families. As a result, it is really challenging to determine exactly what the impact of that expansion was.    Dr. Sullivan. Yes. I agree with you, but let me be clear on what I am pushing here, is that I would like to have the solid scientific evidence that shows that food stamps is improving nutritional outcomes so that we can put an end to this debated question that some people saying that it is effective, some people are saying that it is not. If we can generate the kind of evidence that will convince policymakers and other stakeholders that it is clearly effective, then it is much easier to design policies and expand them.    Dr. Sullivan. Yes.    Dr. Sullivan. Sure. So there are lots of administrative data that give us information on SNAP, and many other programs, that allow us to track participation in the program, and other things like earnings, employment, et cetera. And what I was commentating on, in terms of administrative data, is that this provides an incredible opportunity to determine the impact of these programs.    So, for example, if I want to know what the effect of SNAP is on employment, I could write a survey and track down SNAP participants and non-participants, but that would be really expensive, and hard to do, but administrative data from UI earnings records already has those outcomes for us. And if I were able to have access to those kinds of data, it would make it much easier for us to conduct these kinds of experiments. When I referred to the Ryan-Murray Act, that is an effort to create a commission to really explore broader ways to create greater access to this. And the end result of that is that we have better information, and from better information we end up having better policy.    Dr. Sullivan. I would agree with Mr. Baron. I might start by just saying that there is a lot of good information and research out there on the SNAP Program. We know a lot about the SNAP Program, like what drives changes in caseloads, and that the macroeconomy plays a large role. We know that SNAP is fairly well targeted, and that a lot of people who receive SNAP are at or near the poverty line.    But when I say things like there isn't a lot of hard evidence on the impact of SNAP, I am talking about what Mr. Baron was referring to, that there is a lack of this kind of experimental evidence that would provide the convincing evidence that would shape policy.    Dr. Sullivan. Thank you. Let me address the second one, because it is closely related to what Mr. Baron was saying, and that is at the Wilson Sheehan Lab, we sometimes refer to this as innovate, evaluate, replicate. So these pilots are an effort to incentivize innovation, so we see state agencies experimenting with new things. We need to rigorously evaluate these pilots, and that is what is being done, and we need to continue to encourage that kind of rigorous evaluation, and then use that research to inform future decisions. So if the pilot is working, then we use that information to scale it up. We say, these are the kinds of programs that are worth investing more dollars in.    If the pilot is not working, that doesn't necessarily mean that we shut it down right away. When we are working with an agency doing an evaluation, the first question we ask when we get modest or negative evidence is why? Why is the evidence not as promising as we had hoped, and can the evidence help us steer or redirect a program in a way to make it better? So the evidence is an opportunity to improve the impact of the programs that we are designing.    Now, if a program continues to demonstrate--or lack to demonstrate effectiveness, then that is when we start thinking about reallocating resources towards programs and pilots that have actually demonstrated real impact.    Dr. Sullivan. Well, the pilots are a nice place to start, and what I would encourage is the opportunity to build off of that. And there are other models in other agencies. The U.S. Department of Education has a good model, a tier-based model that, once there is a pilot that has demonstrated effectiveness, there are funds available to scale that pilot up, and then evaluate it again. And then, when there continues to be evidence of effectiveness, then we scale it up even further, say within a large scale demonstration project. So there is this gradual accumulation of evidence so that we can support better policy.    The Chairwoman. Thanks. The chair now recognizes Congresswoman Lujan Grisham, for 5 minutes. And again, I apologize, we are up against another vote.