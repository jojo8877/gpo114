    Ms. De Mooy. Chairwoman Comstock, Chairman Loudermilk, Ranking Member Lipinski, Ranking Member Beyer, and Members of the Committee, thank you for the opportunity to come here today and testify on behalf of the Center for Democracy and Technology.    CDT is a nonpartisan, nonprofit technology policy advocacy organization dedicated to protecting civil liberties and human rights on the internet, including privacy, free expression, and access to information. I currently serve as the Deputy Director of CDT's Consumer Privacy Project.    We welcome the attention the Committee has given to be pressing issues of consumer data privacy and security through the lens of data sharing on HealthCare.gov. I will review first the data-sharing practices on HealthCare.gov, discuss the privacy and security concerns that these bring up, and make five concrete recommendations for the government to address these concerns.    Several weeks ago, the security firm Catchpoint Systems found that user information was being shared with over 50 entities on HealthCare.gov without user knowledge or permission. When citizens visit HealthCare.gov to learn more about the programs offered to them under the Affordable Care Act, they are asked to give certain pieces of personal information order to show which health insurance plans they qualify for. After submitting this information, HealthCare.gov then surprisingly sent a referral URL to an array of third parties that included some of this information that the consumers had submitted to the site, including parental status, ZIP code, and annual income. This information is used both by websites themselves and third parties for website analytics, as well as for advertising and marketing purposes, also known as retargeting.    For HealthCare.gov administration officials have said that the refer URL was directed to third parties in order to give consumers a simpler, more streamlined, and intuitive experience, and this is doubtless true. However, the government's decision to work with outside vendors allowed private companies to access user information without their knowledge or consent. It is not clear if HealthCare.gov used tracking technologies for retargeting purposes but it appears likely to have played a role.    The use of retargeting in order to increase awareness of and enrollment in available health insurance plans would have been an understandable goal for the government. It is not, however, a free pass for the government to share user information and characteristics with an array of third-party commercial entities, without permission.    Sharing of personal information with third parties is a privacy concern for several reasons. People who visit government websites often do not have a choice. They must visit a designated online place in order to access specific government products and services. Personal data is valuable. When personal information is collected and shared, it is often combined with other data to build individual profiles. This profile is used to target products and services to you and is increasingly also used to create consumer scores that function similarly to credit scores. Health information in particular is sold for a high premium on underground markets, some experts estimate up to $40 to $50 a record, because it is fairly easy to monetize for criminals seeking to bill expensive medical items to Medicaid, for example, or to commit medical identity theft. The theft or use of health information is much harder to recognize and stop than the theft of financial data and more difficult for victims to seek redress.    The number of third-party content providers loading code into the browsers of visitors on HealthCare.gov poses serious security issues. Researchers have pointed to third-party content as one of the primary ways for websites to be infected with malware. Hackers wishing to compromise the integrity of third-party content providers can accomplish a wide range of attacks from simply changing the content of the page to capturing user information and credentials like passwords.    There is no evidence that personal information from HealthCare.gov has been misused but the number of outside parties that can load content and that can see personal information about users is troubling.    Overall, the privacy and security missteps taken by HealthCare.gov were avoidable. We recommend that the government immediately take the following steps: 1) follow sensible guidance available to them and to Office of Management and Budget documents on third-party sharing; 2) implement the six recommendations to protect user privacy and security on HealthCare.gov made in a 2014 report by the Government Accountability Office; 3) strengthen HealthCare.gov's privacy policy limiting third-party sharing only to which it needs to function; 4) implement in-house analytic software that does not report user data back to the software maker; 5) honor the wishes of consumers that express a preference in their browsers not to be tracked.    Ultimately, Congress can best protect consumer information by strengthening legal incentives for companies to better safeguard data and by enacting comprehensive data privacy legislation to give users more control over how their information is collected and used.    Thank you.    Ms. De Mooy. Yes, thank you for the question. I think from a consumer perspective the way that people would have found out about this was through the privacy policy, and we found a lot of problems with the HealthCare.gov privacy policy. For example, it is very broad and very vague. They don't define personally identifiable information and there are guidelines in NIST for defining this, but the impetus is on the privacy policy to sort of define it for itself so that there aren't any loopholes in which data can fall through. So that would have been very helpful. That would have been a form of transparency that would have allowed people to understand a little bit more.    Also, the privacy policy kind of deferred to the privacy policies of the third parties. So it was--the onus was on the consumers or the visitors of the site to find out the policies then of the third parties, which is a little disingenuous considering that many of people had no idea that these third parties were there in the first place.    Chairwoman Comstock. You know, if one of the reasons why they are doing this is they are trying to reach more people to say hey, you might be eligible, you know, whatever you are doing, aren't there other much safer ways to do that? Like, say, you know, if we know a particular ZIP code has a high density of uninsured people, you can--I mean would it expose anyone's privacy if you were maybe advertising online to somebody in their ZIP code or, you know, you were doing outreach efforts that are targeted to targeted populations? Is there a way--what is the best--you know, sort of best practices on doing that in a way that secures people's privacy?    Ms. De Mooy. Sure. Yes, Chairwoman, I think that the way that you put it is exactly right, that there are ways to limit it to certain data points so that you are not getting unnecessary data in order to do things like retargeting. And yes, there are very good reasons why the government, to fulfill its mandate, would need to do outreach to try to get more enrollment, to try to get people aware of these programs.    That said, I think the way that my fellow witness here put it, it was overkill. There was no need for the leakage that occurred. And I think some of this is governed by the contracts that existed between the government and the vendors that they used, and I think it would be very helpful for when the government witnesses are here to find out exactly what the terms of those contracts were in terms of data sharing.    Ms. De Mooy. Thank you for the question. It is a great question and is sort of begins at the layers of communication that occur when you go onto the web. Some of them are behind the scenes and some of them are more apparent. It is rampant on the web certainly with commercial websites but even, you know, all sorts of entities. Data sharing is absolutely aggressive. So in terms of protections, there are very few. There are settings that you can place on browsers that restrict or at least broadcast the fact that you would not like to be tracked, but those are sort of on the honor system right now, which makes it difficult to enforce.    But just to get back to your technical question, when you are online and say, for example, you click on a link or you go to a website, it will trigger a message from your browser to the intended website's server and that sort of announces your arrival to them and it will share basic information about you like your IP address, which I think most people know but it is sort of like your telephone number is your address on the telephone network. Your IP address is your address on the internet. And the information exchanged usually during this point is just utilitarian, sort of what does your browser support so that the website will load correctly?    When a website wants to customize this and wants to sort of remember who you are and remember certain places that you may have gone, things you are interested in, which is how we put customization, they may enact third parties and that may involve dropping a cookie, which is sort of a little recorder is the way I like to think of it, onto your computer and that will observe where you have been and it will also observe where you are going to, so different websites the you are surfing to. And if the site wants to do marketing and advertising, they will employ third parties and they will have different contracts. And this can be up into the hundreds and thousands for some sites.    Ms. De Mooy. Well, it is a lucrative business and data miners and advertising networks work in real time, and so the time that you are online may feel slow to you but to the advertising networks, they are grabbing millions and trillions of data points every single second. And so that is monetized then into serving advertisements. So the more, the merrier.    Ms. De Mooy. Um-hum.    Ms. De Mooy. To me that is inexplicable to be quite honest. I can tell you that the rationale would probably include web customization, so wanting, as they said, to make the site more streamlined, more intuitive for people so that it is easier to find access to the information they are looking for. In other words, if a consumer comes to a website and they really just want to see the plan rates, but the website will serve that to them the next time and it sort of remembers that.    The act of having--especially for a government website--that many entities in order to do something like retargeting to me is inexplicable. I think it is an example--and this is just speculation--is an example of when you have multiple different contractors working on a project, this was sort of the easiest and kind of laziest way to design the site, to do--there are ways to do it in-house and there are ways to do it in a more privacy-protective manner, but that was not done here.    Ms. De Mooy. Yes.    Ms. De Mooy. That is correct----    Ms. De Mooy. --as far as I know.    Ms. De Mooy. That is correct, sir.    Ms. De Mooy. I am not quite sure what the question was.    Ms. De Mooy. My understanding of the Open Data Initiative is a bit different. It is more about actionable data that can be used to help the public or for the public. It is more about transparency. And in this case, transparency would have been very helpful. I think that the fact that people have no choice when they come is a serious problem that should have held the government to a higher standard in terms of protecting their privacy and security.    Ms. De Mooy. Um-hum.    Ms. De Mooy. In my opinion, no. I think the government--I can't speak for what the intentions were. I don't have any direct knowledge of that, but I can say that my understanding of the Open Data Initiative was about giving citizens more opportunities for actionable data, more transparency in the government, and I think in this case it had more to do with the function of the site, which was to reach as many people as possible, to, you know, do some advertising and marketing to get to the populations that would be interested in this. And I think they went far beyond what was necessary and far beyond what their own government has suggested and prescribed.    Ms. De Mooy. I am sorry. I just had one additional comment to make, sir.    Just--I think The Open Data Initiative should be coupled with the understanding that trust is necessary. The people needed to have trust in the systems and particularly when it comes to healthcare Americans shouldn't have to choose between privacy and health.    Ms. De Mooy. Right, and perhaps proverbial--    Ms. De Mooy. Well, I appreciate that analogy. I don't have any knowledge about the mechanisms that went on. I can speculate that when you hire a lot of outside vendors to work on one project, that the communications can fall apart. And I think in this case, when I look at the site design, it feels to me a bit lazy. And like I said before, the easiest thing is to just allow rampant sharing. It is a little more technical and in fact more well-designed to limit that sharing.    Yes, the government could do some of the analytics, definitely the analytics in-house. They could create sharing buttons. They could have, you know, really ironclad privacy policy that includes privacy policies for their third parties as opposed to sort of adopting the policies of their third parties.    Ms. De Mooy. Correct.    Ms. De Mooy. We are waiting on the White House. They had said that they would release it 45 days after the President's State of the Union address.    Ms. De Mooy. Thank you for the question. I think the reason that I would imagine that the government would give for doing retargeting, which, as I said before, it isn't certain--it appears to be likely but it is uncertain--the reason they would have done that would be to find the people who needed the information, so to reach into communities where people who don't have health insurance live, go to the sites, and the way that they would learn this is by, you know, sharing the information and learning where people come from to where they first learned about it and link to the site and go and making sure that they are advertising at that site.    One of the problems with that in terms of--from a privacy advocacy perspective is that when you reach into communities such as those that don't have health insurance, you are often reaching into communities that are disadvantaged, and there have been studies and surveys that show that people who are disadvantaged tend to suffer more privacy harms in terms of being labeled. I know the Senate Commerce Committee report came out that identified some of these labels has ``urban and barely making it,'' ``second city ethnic,'' things that are insulting to say the least but also can actually accelerate the cycle of poverty by sending things like predatory loans and different sorts of interest rates.    Ms. De Mooy. Yes, sir. Generally, this is done through a privacy policy, which I would imagine most of us in here don't read. I know that I have been guilty of that. They are very lengthy usually in sort of a legalese that is difficult for most people to wade through. So we almost always agree if it is something that preempts joining a service or a site.    The government in this case should be held to a higher standard than that in my opinion not just because the government should be the steward of privacy and security but also because, as I said, people don't have a choice. They need to go to this website and they should have been given a choice about whether to share their data.    Ms. De Mooy. Thank you so much for the question.    The government needs to implement the recommendations that I outlined my testimony that include guidance from OMB that really lays out exactly how a government should interact with third parties. It is very privacy-protective. It is also practical in terms of using sharing technologies, using web analytics technologies.    And also my fellow witness brought up and I should mention the GAO report in 2014, which appears to have been ignored. I am not sure exactly if that is the truth, and it would be really good to hear from the Administration on the progress, but those are also excellent privacy and security guidances that the report gave. So I would say that that would be a good start. And it is actually--as opposed to a data breach, it is something the government can do right now.    Ms. De Mooy. Honestly, no. There have quite a few reports and studies done and I think almost every aspect of this has been looked at and picked apart either by academics or technologists or advocates. I think simply entities, government entities, commercial entities, need to take privacy insecurities very seriously and not view the opportunities to get data as, ``I will collect as much as I can and then figure out what to do with it later,'' but to have very solid systems in place that include privacy risk assessments and privacy model threats, which is, you know, something that is a sort of a wonky thing to say but is actually very useful, even for the average person to consider what data may be getting out there about you, to really take the resources that are available online to look at your data profile. There are some companies that allow that. There are some that give you sort of your advertising profile.    Those resources are helpful but I think really the onus is on especially the government to lead the way by having the highest standard of privacy and security and then to create legal incentives for companies to protect and safeguard user data.    Ms. De Mooy. Sir, I think one thing that would help would be some transparency into the system, which there is very little of it right now. Second, I would just say that HIPAA didn't apply in this case. The HealthCare.gov website was not a covered entity, which is--HIPAA is, you know, a really complicated law. I struggle to understand it. But I know that it did not fall under the categories of covered entities.    Ms. De Mooy. My reaction is that the government should immediately implement some of these recommendations to make sure that no, as I said, American should have to choose between their data sharing and their health.    Ms. De Mooy. I think that is difficult to say. I think there is a deadline looming and so the government has tried to get as many people who need this service to make sure that it is in front of them and available to them. But the fact that they have reduced data sharing is good; they just need to do more.    Ms. De Mooy. I don't think that is true. It is something that I hear quite a bit and I usually hear from people who have curtains and people who like to wear pants, for example, sort of not clever way but people care about privacy. It is a part of autonomy. It is at the heart of it. And when you take that autonomy away, in this example, where the government didn't ask or get permission, then you are removing a fundamental right that we have.    I think there are steps that--especially in the case of HealthCare.gov--that can be taken to ensure more privacy, to ensure autonomy and freedom, and so that when people go, they have the option of whether they want to share this kind of data. Certainly in the health context it is more sensitive.    I think companies have options. I think privacy is in itself an innovation. To speak to your point about making sure that we don't limit innovation, you know, the internet, I remember a time when the internet was not something that people used to buy things from. It was literally too scary to do that but privacy became an innovation that allowed that to happen.    Ms. De Mooy. And I think in this atmosphere of data sharing, rampant data sharing, that needs to happen once again.    Ms. De Mooy. Sir, I think that is something I could get to you in writing. In our written testimony that sort of lays out some of our recommendations. And CDT has done quite a bit of work on policy in that and I think I would do it a disservice to sum it up now. But I can say that in the President's comprehensive Consumer Privacy Bill of Rights, what that did was create a framework for legislation around the fair information practice principles, which have guided privacy and security for decades and are sort of renowned as something that is flexible and nimble enough to address new technologies. I think that would be a start for there to be sort of a baseline consumer privacy legislation, something that we have been sorely lacking in the United States.    Ms. De Mooy. Absolutely. I think data minimization is a term that we use to describe when a company has a purpose for collecting a data point and that it stops collecting after that purpose has been fulfilled. It is a kind of simple concept but one that is lost, especially in the rampant data collection online. So implementing a real understanding of why you need a piece of data and not just collecting every single piece that you can get would drastically reduce the risks to people in terms of security and privacy.    Ms. De Mooy. Data minimization?    Ms. De Mooy. To my understanding, no. I think data systems are designed from the beginning, and when they use privacy principles such as data minimization, it is very possible. You know, there is really no system that I know of the needs every single thing about you in order to function. Usually we use services and apps for a specific purpose. And so I think that is absolutely doable.